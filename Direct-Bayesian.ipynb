{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": [
     "Overview"
    ]
   },
   "source": [
    "# Direct Regression - Bayesian Version\n",
    "\n",
    "## Response Model\n",
    "\n",
    "How well can we predict outcomes $Y$ conditional on treatment $T$ and other covariates $Z$?\n",
    "\n",
    "### Treatent variables\n",
    "\n",
    "   - **reduhl**\tCompleted re-education based on highest level of attainment\n",
    "   - **redudl**\tCompleted re-education based on detailed qualifications\n",
    "   - **redufl**\tCompleted re-education using highest lvl and detailed qualifications.\n",
    "\n",
    "### Outcome variables\n",
    "   - Mental health in 2019 (**mh**). This is the transformed mental health scores from the aggregation of mental health items of the SF-36 Health Survey, as reported by the individual in 2019. It ranges from 0 to 100, with higher scores indicating better mental health.  \n",
    "   - Working hours in 2019 (**wkhr**) records the total number of hours the individual works in all jobs in a week on average. Working hours are set to 0 for those not working. \n",
    "   - Hourly Wages in 2019 (**rlwage**) records the average hourly wage for the individualâ€™s main job in 2019. Hourly wages are set to 0 for those not working and set to missing for those reporting working more than 100 hours a week. \n",
    "   \n",
    "#### Columns explicitly excluded\n",
    "   - **xwaveid** (unique identifier)\n",
    "   - **p_rcom*** (timing of completion of re-education, proxies treatment) TODO think about how we would include this\n",
    "   - **p_cotrl** (first avail 2003)\n",
    "   - **p_rdf*** (first avail 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "from scipy.stats import norm, mstats\n",
    "from estimators import BayesianRidgeStat\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, Matern, DotProduct\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from reed import drop_missing_treatment_or_outcome, Model, transform_outcome\n",
    "from direct_regression import seperate_and_transform_data, print_unconditional_effects\n",
    "\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor) # set the default to float64\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "log_outcome=True\n",
    "standardize_outcome=True\n",
    "exclude_patterns = [\n",
    "    '^reduhl$', '^rehllt$', '^redudl$', '^redufl$', '^redllt$', '^refllt$',\n",
    "    '^rlwage$', '^mh$', '^mhbm$', '^wkhr$', '^y_', '^p_rcom','^p_rdf','^p_cotrl',\n",
    "    '^xwaveid$','p_rcom18','^aedcq', '^abnfsty','^aedcqfpt','^aedqstdy'\n",
    "]\n",
    "data_load_func = lambda filepath: pd.read_csv(filepath, index_col='xwaveid')\n",
    "\n",
    "#configuration_name = 'default'\n",
    "outcome = 'y_wsce'\n",
    "treatment = 'redufl'\n",
    "test = False\n",
    "data_file = \"data/all_lasso_selected_100.csv\"\n",
    "xval_gp = False\n",
    "laplace_prior = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data = data_load_func(data_file)\n",
    "drop_missing_treatment_or_outcome(data, treatment, outcome)\n",
    "data[outcome] = transform_outcome(data[outcome],log_outcome, standardize_outcome)\n",
    "\n",
    "    \n",
    "plt.hist(data[outcome])\n",
    "plt.xlabel(outcome)\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Distribution of outcomes\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Prepare data for modeling\n",
    "\n",
    "- split into treated/control\n",
    "- impute missing values and scale\n",
    "- separate features from outcomes&treatments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from direct_regression import seperate_and_transform_data\n",
    "X0, X1, y0, y1, X, y, t, features = seperate_and_transform_data(data, treatment, outcome)\n",
    "print(\"Control data dimensions: \", X0.shape)\n",
    "print(\"Treated data dimensions:\", X1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Compute unconditional/unadjusted estimate of treatment effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_unconditional_effects(data, treatment, y0, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Statsmodels\n",
    "\n",
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Xt = np.hstack((t[:, np.newaxis], X))\n",
    "Xt = pd.DataFrame(data=Xt, columns=[\"treatment\"] + features)\n",
    "ols = sm.OLS(y, sm.add_constant(Xt))\n",
    "res = ols.fit()\n",
    "ate_ols = res.params.loc[\"treatment\"]\n",
    "ci_ols = res.conf_int().loc[\"treatment\"]\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Scikit learn Bayesian Estimators\n",
    "\n",
    "### Bayesian Ridge\n",
    "\n",
    "Coefficient statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "blr = BayesianRidgeStat()\n",
    "blr.fit(Xt, y)\n",
    "\n",
    "score = blr.score(Xt, y)\n",
    "\n",
    "# Coefficient statistics\n",
    "stats = blr.model_statistics()\n",
    "ate_blr, se_blr = stats.beta[0], stats.std_err[0]\n",
    "ci_blr = norm.interval(loc=ate_blr, scale=se_blr, alpha=0.95)\n",
    "\n",
    "print(\"Bayesian Ridge simple model - coefficient stats:\")\n",
    "print(f\"  R-squared = {score:.4f}\")\n",
    "print(f\"  ATE: {ate_blr:.4f} ({se_blr:.4f})\")\n",
    "print(f\"  t: {stats.t_stat[0]:.4f}\")\n",
    "print(f\"  p-value: {stats.p_value[0]:.4f}\")\n",
    "print(f\"  CI (0.025, 0.975): [{ci_blr[0]:.4f}, {ci_blr[1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "ATE sampling with counterfactual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATE sampling\n",
    "samples = 100\n",
    "w_samples = np.random.multivariate_normal(mean=blr.coef_, cov=blr.sigma_, size=samples).T\n",
    "\n",
    "n = len(X)\n",
    "Xt0 = pd.DataFrame(data=np.hstack((np.zeros((n, 1)), X)), columns=[\"treatment\"] + features)\n",
    "Xt1 = pd.DataFrame(data=np.hstack((np.ones((n, 1)), X)), columns=[\"treatment\"] + features)\n",
    "\n",
    "ate_blr_samples = np.mean(Xt1 @ w_samples, axis=0) - np.mean(Xt0 @ w_samples, axis=0)\n",
    "ate_blr = ate_blr_samples.mean()\n",
    "se_blr = np.std(ate_blr_samples, ddof=1)\n",
    "ci_blr = norm.interval(loc=ate_blr, scale=se_blr, alpha=0.95)\n",
    "\n",
    "print(\"Bayesian Ridge simple model - counterfactual sampling:\")\n",
    "print(f\"  R-squared = {score:.4f}\")\n",
    "print(f\"  ATE: {ate_blr:.4f} ({se_blr:.4f})\")\n",
    "print(f\"  CI (0.025, 0.975): [{ci_blr[0]:.4f}, {ci_blr[1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = WhiteKernel() + Matern(nu=1.5)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "# This takes a while for 5000 samples... (5 mins or so)\n",
    "gpr.fit(Xt, y)\n",
    "score = gpr.score(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATE sampling   \n",
    "f0, K0 = gpr.predict(Xt0, return_cov=True)\n",
    "f1, K1 = gpr.predict(Xt1, return_cov=True)\n",
    "\n",
    "y_0_samples = np.random.multivariate_normal(mean=f0, cov=K0, size=samples)\n",
    "y_1_samples = np.random.multivariate_normal(mean=f1, cov=K1, size=samples)\n",
    "ate_gp_samples = (y_1_samples - y_0_samples).mean(axis=1)\n",
    "\n",
    "ate_gp = ate_gp_samples.mean()\n",
    "se_gp = np.std(ate_gp_samples, ddof=1)\n",
    "ci_gp = norm.interval(loc=ate_gp, scale=se_gp, alpha=0.95)\n",
    "\n",
    "print(f\"Gaussian Process {gpr.kernel_}:\")\n",
    "print(f\"  R-squared = {score:.4f}\")\n",
    "print(f\"  ATE: {ate_gp:.4f} ({se_gp:.4f})\")\n",
    "print(f\"  CI (0.025, 0.975): [{ci_gp[0]:.4f}, {ci_gp[1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Check if GP is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if xval_gp:\n",
    "    cv_scores = cross_validate(gpr, Xt, y,\n",
    "                               cv=KFold(n_splits=5, shuffle=True),\n",
    "                               return_train_score=True)\n",
    "    pd.DataFrame(cv_scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Hierarchical Bayesian Linear Model\n",
    "\n",
    "This model takes the following form and prior settings,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\{\\lambda_0, \\lambda_t, \\lambda_x, \\lambda_{tx}\\} &\\sim \\textrm{Gamma}(1, 1) \\\\\n",
    "    \\sigma^2 &\\sim \\textrm{Gamma}(1, 1) \\\\\n",
    "    w_0 &\\sim \\mathcal{N}(0, \\lambda_0) \\\\\n",
    "    w_t &\\sim \\mathcal{N}(0, \\lambda_t) \\\\\n",
    "    \\mathbf{w}_x &\\sim \\mathcal{N}(0, \\lambda_x \\mathbf{I}_d) \\\\\n",
    "    \\mathbf{w}_{tx} &\\sim \\mathcal{N}(0, \\lambda_{tx} \\mathbf{I}_d) \\\\\n",
    "    y_i &\\sim \\mathcal{N}(\\mu(\\mathbf{x}_i, t_i), \\sigma^2) \\\\\n",
    "    \\mu(\\mathbf{x}_i, t_i) &= w_0 + w_t t_i + \\mathbf{w}_x^\\top\\mathbf{x}_i + t_i\\mathbf{w}_{tx}^\\top\\mathbf{x}_i\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w_0, w_t, w_x, w_tx, x, t):\n",
    "    f = w_0 + w_t * t + x.matmul(w_x.T) + t * x.matmul(w_tx.T)\n",
    "    return f\n",
    "\n",
    "\n",
    "def model_treatment_intersection(x, t, y):\n",
    "    # Hyper-Priors\n",
    "    lambda_prior = dist.Gamma(1., 1.)\n",
    "    sigma_prior = dist.Gamma(1., 1.)\n",
    "    \n",
    "    # Priors\n",
    "    n, d = x.shape\n",
    "    weight_prior = dist.Laplace if laplace_prior else dist.Normal\n",
    "    p_w0 = weight_prior(0, pyro.sample(\"l_0\", lambda_prior))\n",
    "    p_wt = weight_prior(0, pyro.sample(\"l_t\", lambda_prior))\n",
    "    p_wx = weight_prior(torch.zeros(d), pyro.sample(\"l_x\", lambda_prior) * torch.ones(d))\n",
    "    p_twx = weight_prior(torch.zeros(d), pyro.sample(\"l_tx\", lambda_prior) * torch.ones(d))\n",
    "    \n",
    "    # Model weights\n",
    "    w_0 = pyro.sample(\"intercept\", p_w0)\n",
    "    w_t = pyro.sample(\"treatment\", p_wt)\n",
    "    w_x = pyro.sample(\"confounders\", p_wx)\n",
    "    w_tx = pyro.sample(\"intersection\", p_twx)\n",
    "    \n",
    "    # Likelihood\n",
    "    f = predict(w_0, w_t, w_x, w_tx, x, t)\n",
    "    sigma = pyro.sample(\"variance\", sigma_prior)\n",
    "    \n",
    "    with pyro.plate(\"data\", n):\n",
    "        likelihood = dist.Normal(f, sigma)\n",
    "        y = pyro.sample(\"likelihood\", likelihood, obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Run MCMC inference to compute the posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 500\n",
    "warm_up = 200\n",
    "\n",
    "X_torch = torch.tensor(X)\n",
    "t_torch = torch.tensor(t)\n",
    "y_torch = torch.tensor(y)\n",
    "\n",
    "\n",
    "# Initialize No U-Turn Sampler\n",
    "nuts_kernel = NUTS(model_treatment_intersection, max_tree_depth=7)\n",
    "model_mcmc = MCMC(nuts_kernel, num_samples=samples, warmup_steps=warm_up)\n",
    "\n",
    "# Run the sampler\n",
    "model_mcmc.run(X_torch, t_torch, y_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Sample the ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbr_samples = model_mcmc.get_samples()\n",
    "w_0s = hbr_samples[\"intercept\"]\n",
    "w_ts = hbr_samples[\"treatment\"]\n",
    "w_xs = hbr_samples[\"confounders\"]\n",
    "w_txs = hbr_samples[\"intersection\"]\n",
    "\n",
    "ate_hlr_samples = np.zeros(samples)\n",
    "score_samples = np.zeros(samples)\n",
    "t0 = torch.zeros_like(t_torch)\n",
    "t1 = torch.ones_like(t_torch)\n",
    "\n",
    "for s in range(samples):\n",
    "    f = predict(w_0s[s], w_ts[s], w_xs[s], w_txs[s], X_torch, t_torch)\n",
    "    f1 = predict(w_0s[s], w_ts[s], w_xs[s], w_txs[s], X_torch, t1)\n",
    "    f0 = predict(w_0s[s], w_ts[s], w_xs[s], w_txs[s], X_torch, t0)\n",
    "    ate_hlr_samples[s] = f1.mean() - f0.mean()\n",
    "    score_samples[s] = r2_score(y, f)\n",
    "\n",
    "ate_hlr = ate_hlr_samples.mean()\n",
    "ci_hlr = mstats.mquantiles(ate_hlr_samples, prob=[0.025, 0.975])\n",
    "\n",
    "print(\"Hierarchical Linear Regression\")\n",
    "print(f\"  R-squared = {score_samples.mean():.4f} ({score_samples.std():.4f})\")\n",
    "print(f\"  ATE: {ate_hlr:.4f}\")\n",
    "print(f\"  CI (0.025, 0.975): [{ci_hlr[0]:.4f}, {ci_hlr[1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "cnt, *_ = plt.hist(ate_hlr_samples, bins=20)\n",
    "plt.plot([ate_hlr, ate_hlr], [0, max(cnt)], 'r', label=\"mean\")\n",
    "plt.title(\"HLR ATE samples\")\n",
    "plt.xlabel(\"ATE\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Plot ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ate_labels = [\"OLS\", \"Bayesian Linear\", \"Gaussian Process\", \"Hierarchical Linear\"]\n",
    "ate = [ate_ols, ate_blr, ate_gp, ate_hlr]\n",
    "ci = [ci_ols, ci_blr, ci_gp, ci_hlr]\n",
    "ind = np.arange(len(ate))\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.vlines(ind, ymin=[c[0] for c in ci], ymax=[c[1] for c in ci], colors='k', linewidth=3)\n",
    "plt.plot(ind, ate, 'rx', markersize=10)\n",
    "plt.xticks(ind, labels=ate_labels, rotation=30)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
