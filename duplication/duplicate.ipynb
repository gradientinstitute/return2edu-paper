{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('default')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import make_regression, load_boston\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GroupKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import check_cv\n",
    "import duplicate as dp\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# https://altair-viz.github.io/user_guide/display_frontends.html#displaying-in-the-jupyter-notebook\n",
    "# alt.renderers.enable('mimetype') # works off-line\n",
    "# alt.renderers.enable('notebook') \n",
    "alt.renderers.enable('default') # recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jack/Documents/GitHub/re-education\n",
      "/Users/jack/Documents/GitHub/re-education/duplication\n"
     ]
    }
   ],
   "source": [
    "# get bootstrap.py from parent directory\n",
    "%cd ..\n",
    "import bootstrap as bs\n",
    "import reed as reed\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_0</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>X_10</th>\n",
       "      <th>X_11</th>\n",
       "      <th>X_12</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X_0   X_1   X_2  X_3    X_4    X_5   X_6     X_7  X_8    X_9  X_10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "     X_11  X_12     y  \n",
       "0  396.90  4.98  24.0  \n",
       "1  396.90  9.14  21.6  \n",
       "2  392.83  4.03  34.7  \n",
       "3  394.63  2.94  33.4  \n",
       "4  396.90  5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_boston(return_X_y=True)#make_regression(n_samples=1000,n_features=4, noise=0, random_state=0)\n",
    "\n",
    "feature_names = [f'X_{i}' for i in range(X.shape[1])]\n",
    "data = pd.DataFrame(data=X, columns=feature_names)\n",
    "data['y'] = y\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_duplicates = 4\n",
    "n_splits = 5\n",
    "base_groups = np.arange(y.size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_dup, y_dup, weights_dup, groups_dup = dp.simple_duplicate(X_train, y_train, n_duplicates)\n",
    "\n",
    "scoring = {\n",
    "    \"MSE\": make_scorer(metrics.mean_squared_error),\n",
    "    \"R2\": make_scorer(metrics.r2_score),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom CV with groups\n",
    "boost = GridSearchCV(\n",
    "    # LinearRegression(),\n",
    "    GradientBoostingRegressor(random_state=0,),\n",
    "    # reed.StatsmodelsOLS(),\n",
    "    param_grid={},\n",
    "    cv=GroupKFold(n_splits=n_splits),\n",
    "    \n",
    "    \n",
    ")\n",
    "boost_dup = GridSearchCV(\n",
    "    # LinearRegression(),\n",
    "    GradientBoostingRegressor(random_state=0),\n",
    "    # reed.StatsmodelsOLS(),\n",
    "    param_grid={}, \n",
    "    cv=GroupKFold(n_splits=n_splits),\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# output = cross_validate(\n",
    "#     boost,\n",
    "#     X,\n",
    "#     y,\n",
    "#     groups=base_groups,\n",
    "#     scoring=scoring,\n",
    "#     cv=dp.group_k_fold_unique_test_groups(X, y, base_groups, n_splits),\n",
    "# )\n",
    "\n",
    "# output_dup = cross_validate(\n",
    "#     boost_dup,\n",
    "#     X_dup,\n",
    "#     y_dup,\n",
    "#     groups=groups_dup,\n",
    "#     fit_params={\"sample_weight\": weights_dup},\n",
    "#     scoring=scoring,\n",
    "#     cv=dp.group_k_fold_unique_test_groups(X_dup, y_dup, groups_dup, n_splits),\n",
    "# )\n",
    "\n",
    "\n",
    "def mean_var_cv_out(cv_out):\n",
    "    means_vars = {}\n",
    "    for k, v in cv_out.items():\n",
    "        means_vars[k + \"_mean\"] = np.mean(v)\n",
    "        means_vars[k + \"_var\"] = np.var(v)\n",
    "    return means_vars\n",
    "\n",
    "\n",
    "# mean_var_cv_out(output), mean_var_cv_out(output_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models, using bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done un-duplicated\n"
     ]
    }
   ],
   "source": [
    "# use bootstrapping\n",
    "def boost_param_extractor(estimator):\n",
    "    return estimator.get_params()\n",
    "\n",
    "sample_weight= weights_dup\n",
    "\n",
    "\n",
    "results = bs.bootstrap(\n",
    "    estimator=boost,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    error_score=\"raise\",\n",
    "    # groups=base_groups,\n",
    "    parameter_extractor=boost_param_extractor,\n",
    "    return_estimator=True,\n",
    "    groups=True,\n",
    "    n_jobs=1,\n",
    "    sample_weight=sample_weight\n",
    ")\n",
    "print(\"Done un-duplicated\")\n",
    "\n",
    "results_dup = bs.bootstrap(\n",
    "    estimator=boost_dup,\n",
    "    X=X_dup,\n",
    "    y=y_dup,\n",
    "    # groups=groups_dup,\n",
    "    parameter_extractor=boost_param_extractor,\n",
    "    return_estimator=True,\n",
    "    n_jobs=1,\n",
    "    groups=True,\n",
    "    sample_weight=sample_weight\n",
    ")\n",
    "\n",
    "# print(results['parameters'])\n",
    "\n",
    "# print(scores)\n",
    "# for score_dict in scores:\n",
    "#     estimator = score_dict[\"estimator\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate, compare models\n",
    "Evaluate models on the (unduplicated) test data we set aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = results['estimator']\n",
    "models_dup = results_dup['estimator']\n",
    "\n",
    "y_preds, y_preds_dup = ([model.predict(X_test) for model in ms] for ms in (models, models_dup))\n",
    "y_preds, y_preds_dup = np.array(y_preds), np.array(y_preds_dup)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean mse    : 12.670221765225381; mse var    : 2.779869526632825\n",
      "mean dup mse: 10.82670118574453; mse var dup: 0.4808177083378803\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores, scores_dup = ([metrics.mean_squared_error(y_pred, y_test) for y_pred in preds] for preds in (y_preds, y_preds_dup))\n",
    "\n",
    "print(f\"mean mse    : {np.mean(scores)}; mse var    : {np.var(scores)}\")\n",
    "print(f\"mean dup mse: {np.mean(scores_dup)}; mse var dup: {np.var(scores_dup)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take an arbitrary point in the test set; let's see how its performance changes:\n",
    "index = 0\n",
    "point_y_hat = y_preds[:,index]\n",
    "point_y_hat_dup = y_preds_dup[:, index]\n",
    "point_y = y_test[index] * np.ones_like(point_y_hat)\n",
    "\n",
    "point_data = pd.DataFrame(dict(\n",
    "    point_y=point_y,\n",
    "    point_y_hat=point_y_hat,\n",
    "    point_y_hat_dup=point_y_hat_dup,\n",
    "))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg # remove to show figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(point_y_hat, point_y_hat_dup)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel(\"$\\hat{y}$\")\n",
    "plt.ylabel(\"$\\hat{y}$ dup\")\n",
    "\n",
    "plt.savefig('scatter.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we see slightly more accurate estimates with substantially less variance in the errors when using the duplicated data\n",
    "- TODO (after introducing econml model example so as to not prematurely harden the code?): wrap this up into a function that we can pass a model into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart = alt.Chart(data).mark_point().encode(\n",
    "    x='X_0',\n",
    "    y='y',\n",
    "    color='X_1:Q'\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "# un-comment to view\n",
    "# chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = data.corr().stack().reset_index().rename(columns={0: 'correlation', 'level_0': 'variable 0', 'level_1': 'variable 1'})\n",
    "# print(correlations.head())\n",
    "corr_mat = alt.Chart(correlations).mark_rect().encode(\n",
    "    x='variable 0:N',\n",
    "    y='variable 1:N',\n",
    "    color='correlation:Q'\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "combined_fig = alt.concat(\n",
    "chart,\n",
    "corr_mat\n",
    ").resolve_scale(\n",
    "    color='independent'\n",
    ")\n",
    "\n",
    "# un-comment to view\n",
    "# combined_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dda320fae4f182a96bf1d81c2885700f1aa461d83e7ddba765ac5806591340a3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('further-education': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
