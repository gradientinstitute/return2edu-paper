{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import re\n",
    "import string\n",
    "import sklearn\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from reed import *\n",
    "#from cinspect import dependence, importance\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "from econml.orf import DMLOrthoForest, DROrthoForest\n",
    "from econml.dml import CausalForestDML\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCVWrapper, WeightedLasso, WeightedLassoCV\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "\n",
    "\n",
    "# set global notebook options\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 500\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging.config\n",
    "DEFAULT_LOGGING = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    'loggers': {\n",
    "        '': {\n",
    "            'level': 'INFO',\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(DEFAULT_LOGGING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'y_Dwsce'#'y_wsce'\n",
    "treatment = 'redufl'\n",
    "optimisation_metric = 'neg_mean_squared_error'\n",
    "evaluation_metrics = ('r2','neg_mean_squared_error')\n",
    "log_outcome=False\n",
    "data_file = \"all_vars.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file,index_col='xwaveid')\n",
    "drop_missing_treatment_or_outcome(data, treatment, outcome)\n",
    "if log_outcome:\n",
    "    data[outcome] = np.log(data[outcome]+data[outcome].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from direct_regression import seperate_and_transform_data\n",
    "X0, X1, y0, y1, X, y, T, features = seperate_and_transform_data(data, treatment, outcome)\n",
    "\n",
    "print(\"Control data dimensions: \",X0.shape)\n",
    "print(\"Treated data dimensions:\",X1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Basic check on E[Y] and E[Y|T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from direct_regression import print_unconditional_effects\n",
    "print_unconditional_effects(data, treatment, y0, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Separate covariates X into Xh and W\n",
    "\n",
    "EconML requires `X` (covariates with which to compute heterogeneity) to be set, even if you only want to estimate ATE. \n",
    "\n",
    "We will use `Xh` for the covariates passed to $X$ for EconML and `W` for the remaining variables ie `Union(Xh, W) = X`\n",
    "\n",
    "For initial testing, lets just take the feature with the largest coefficient to be the one to compute CATE with respect to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def find_most_predictive_feature(X,T,y,features):\n",
    "    model = Lasso()\n",
    "    V = np.hstack((X,T.reshape(-1,1)))\n",
    "    features_ext = features + ['treatment']\n",
    "    model.fit(V,y)\n",
    "    coef = pd.DataFrame({\"coef\":model.coef_},index=features_ext)\n",
    "    coef['magnitude'] = coef['coef'].abs()\n",
    "    coef_mag = coef.sort_values('magnitude',ascending=False)  \n",
    "    return coef_mag\n",
    "\n",
    "coef_mag = find_most_predictive_feature(X,T,y,features)\n",
    "coef_mag.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "hetero_feature = coef_mag.iloc[0].name\n",
    "print(f\"Computing treatment effect heterogeneity with respect to: {hetero_feature}\")\n",
    "x_indx = features.index(hetero_feature)\n",
    "Xh = X[:,x_indx].reshape(-1,1) # X for EconML models\n",
    "W = np.delete(X,x_indx, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### LinearDML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from econml.dml import LinearDML\n",
    "ldml = LinearDML(discrete_treatment=True)\n",
    "ldml.fit(y,T,X=Xh,W=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldml.ate(X=Xh), ldml.ate_interval(X=Xh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from econml.dml import SparseLinearDML\n",
    "sldml = SparseLinearDML(discrete_treatment=True)\n",
    "sldml.fit(y,T,X=Xh,W=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sldml.ate(X=Xh), ldml.ate_interval(X=Xh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### LinearDR Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from econml.dr import LinearDRLearner\n",
    "ldr = LinearDRLearner()\n",
    "ldr.fit(y,T,X=Xh,W=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldr.ate(X=Xh), ldr.ate_interval(X=Xh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### CausalForestDML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from econml.dml import CausalForestDML\n",
    "cf = CausalForestDML(model_y=Lasso(),\n",
    "                       model_t=LogisticRegression(),\n",
    "                       discrete_treatment=True,\n",
    "                       random_state=123)\n",
    "cf.fit(y, T, X=Xh, W=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.ate(X=Xh), cf.ate_interval(X=Xh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Meta Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from econml.metalearners import TLearner, SLearner, XLearner, DomainAdaptationLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "models = LassoCV(alphas=np.logspace(-2,4,30),max_iter=5000)\n",
    "est_t = TLearner(models=models)\n",
    "est_t.fit(y, T, X=X, inference='bootstrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_t.ate(X=X), est_t.ate_interval(X=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "models = GradientBoostingRegressor()\n",
    "est_t2 = TLearner(models=models)\n",
    "est_t2.fit(y, T, X=X, inference='bootstrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_t2.ate(X=X), est_t2.ate_interval(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - figure out how to set the number of bootstrap samples\n",
    "# TODO - implement manual bootstrapping\n",
    "# TODO - plot CATE\n",
    "# TODO - figure out why we have to set X (look at the implementation in EconML)\n",
    "# TODO - test out some other implementations of DoubleML/CausalForest (maybe in R)\n",
    "# TODO - look at cricism methods on do-why and test them out (see if we can get the same results through the do-why interface)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
