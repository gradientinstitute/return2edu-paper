{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook contains the code to generate the base datasets for later estimation. Steps include;\n",
    "\n",
    "   1. Removing people who do not meet the inclusion criteria (age at wave1, present in both intial and final wave). \n",
    "   2. Computing treatment and outcome variables.\n",
    "   3. Removing features that are deemed to be proxies for the treatment variable\n",
    "   4. Removing columns that are ids or otherwise deemed irrelevant.\n",
    "   5. Optional unsupervised feature selection (with respect to the treatment/target) feature selection to produce smaller datasets and reduce the issue of correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7\n",
      "/home/dsteinberg/.virtualenvs/re-education/bin/python\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import re\n",
    "import string\n",
    "#from sklearn_pandas import DataFrameMapper\n",
    "import networkx as nx\n",
    "import reed, config\n",
    "import pickle\n",
    "from clean import *\n",
    "from reed import regex_select\n",
    "\n",
    "pd.options.display.max_columns=100\n",
    "pd.options.display.max_colwidth=200\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "Set which waves to base the analysis on, what the minimum age must be to be considered and above what threshold a column is excluded due to missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "s,m,e = 'a','q','s' # select which waves to base analysis on\n",
    "min_start_age = 25 # the minimum age people must as of the starting wave\n",
    "missing_threshold = 0.90\n",
    "correlation_threshold = 0.90\n",
    "redundant_threshold=0.9\n",
    "test = False\n",
    "release = config.release"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Data Structure\n",
    "\n",
    "- Part1 contains the combined data from all questionairs asked in a given wave. Each wave is a separate file (eg a s wave 1, be is wave 2, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Filter people who were already studying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people in initial wave 19914\n",
      "Dropping 7359 participants below age 25\n",
      "Dropping 1387 participants already studying at period start\n",
      "Remaining participants:11168\n"
     ]
    }
   ],
   "source": [
    "summary_study = ['aedqstdy','aedfts','acaeft','acaept','anlreast','abncsty','abnfsty']\n",
    "\n",
    "c11_study = [\n",
    " 'aedcqsl',\n",
    " 'aedcqsh',\n",
    " 'aedcqnq',\n",
    " 'aedcqtq',\n",
    " 'aedcqta',\n",
    " 'aedcqtc',\n",
    " 'aedcqc1',\n",
    " 'aedcqc2',\n",
    " 'aedcqc3',\n",
    " 'aedcqc4',\n",
    " 'aedcqcd',\n",
    " 'aedcqad',\n",
    " 'aedcqav',\n",
    " 'aedcqbd',\n",
    " 'aedcqhd',\n",
    " 'aedcqgd',\n",
    " 'aedcqms',\n",
    " 'aedcqdc',\n",
    " 'aedcqbc',\n",
    " 'aedcqsc',\n",
    " 'aedcqcc',\n",
    " 'aedcqgc',\n",
    " 'aedcqcn',\n",
    " 'aedcqdn',\n",
    " 'aedcqnei',\n",
    " 'aedcqna',\n",
    " 'aedcqos',\n",
    " 'aedcqdk',\n",
    "]\n",
    "\n",
    "dv_asced_study = [\n",
    " 'aedcq100',\n",
    " 'aedcq110',\n",
    " 'aedcq120',\n",
    " 'aedcq200',\n",
    " 'aedcq211',\n",
    " 'aedcq221',\n",
    " 'aedcq310',\n",
    " 'aedcq311',\n",
    " 'aedcq312',\n",
    " 'aedcq400',\n",
    " 'aedcq411',\n",
    " 'aedcq413',\n",
    " 'aedcq421',\n",
    " 'aedcq500',\n",
    " 'aedcq511',\n",
    " 'aedcq514',\n",
    " 'aedcq521',\n",
    " 'aedcq524',\n",
    " 'aedcq600',\n",
    " 'aedcq611',\n",
    " 'aedcqunk'\n",
    "]\n",
    "\n",
    "already_studying_cols = summary_study + c11_study + dv_asced_study\n",
    "\n",
    "def filter_participants(df1,min_start_age, already_studying_cols):\n",
    "    \"\"\"\n",
    "    Remove those already studying or below the minimum age in the initial wave.\n",
    "    \"\"\"\n",
    "    n0 = len(df1)\n",
    "    df = df1.loc[df1[f'{s}hgage'] >= min_start_age].copy()\n",
    "    print(f\"Dropping {n0-len(df)} participants below age {min_start_age}\")\n",
    "\n",
    "    # filter out those already studying\n",
    "\n",
    "    already_studying = df[already_studying_cols].sum(axis=1)\n",
    "\n",
    "    n0 = len(df)\n",
    "    df = df[already_studying < 1].copy()\n",
    "    print(f\"Dropping {n0-len(df)} participants already studying at period start\")\n",
    "    print(f\"Remaining participants:{len(df)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# read the combined file for the starting wave\n",
    "sfx = config.release_suffix[release]\n",
    "df1, meta1 = pyreadstat.read_sav(f'data/part1/Combined {s}190{sfx}.sav')\n",
    "n0 = len(df1)\n",
    "print(f\"Number of people in initial wave {n0}\")\n",
    "with open('data/metadata.pkl','wb') as f:\n",
    "    pickle.dump(meta1,f)\n",
    "    \n",
    "df1 = filter_participants(df1,min_start_age, already_studying_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Compute treatment & outcomes\n",
    "#### Outcomes measures\n",
    "   - **hours worked** Largly missing. The following variables are perfectly correlated\n",
    "      - `ajbhru` 57% missing, *E1b Hours per week usually worked in all your jobs*\n",
    "      - `ajbhruc`,57% missing *DV: Hours per week usually worked in all jobs*\n",
    "   - **wages (not normalised by hours worked)**\n",
    "      - `awsfe` wages from all jobs last financial year with imputation from net\n",
    "      - `awsce` current weekly wages from all jobs with imputation from net\n",
    "      - Non-imputed versions of both of these exist (replace the final `e` with `g`) but have slightly more missing values\n",
    "      - `awsfhave` records if people have received income from salary/wages last financial year. We could also use `_esbrd` to tell if people should have a non-zero wage.\n",
    "      - wage variables have quite a lot of missing data (~33% missing `awsfe` and 30% missing both `awsfe` and `awsfhave`)\n",
    "      - There are versions of wage variables with imputation of missing data from based on responses from the participant in other waves and responses from similar participants. These are indicated by the suffix `i` (eg `awsfei`, `awscei`). These variables contain no missing data.\n",
    "   - **employment status (categorical outcome)**\n",
    "   - **mental health**\n",
    "   \n",
    "#### Treatment measures\n",
    "   - Treatment is based on a change in education qualification between 2001 and 2017\n",
    "   - There are a number of study related variables that are only recorded on a subset of the waves. \n",
    "   - _edq{XXX} variables are recorded every year and count the number of qualifications a person holds in each of a number of categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatments: Index(['xwaveid', 'redudl', 'reduhl', 'redufl'], dtype='object')\n",
      "Outcomes: Index(['xwaveid', 'y_jbhruc', 'y_ghmh', 'y_wsce', 'y_wscei', 'y_employment',\n",
      "       'y_Djbhruc', 'y_Dghmh', 'y_Dwsce', 'y_Dwscei', 'y_Demployment'],\n",
      "      dtype='object')\n",
      "Updated computation of treatment\n"
     ]
    }
   ],
   "source": [
    "from treatment_outcomes import compute_treatment_vars, compute_outcomes\n",
    "treatments = compute_treatment_vars(df1, s, m, release)\n",
    "outcomes = compute_outcomes(df1, s, e, release)\n",
    "treatment_outcomes = pd.merge(treatments,outcomes,on='xwaveid',how='inner')\n",
    "treatment_outcomes['xwaveid'] = treatment_outcomes['xwaveid'].astype(int)\n",
    "print(\"Treatments:\",treatments.columns)\n",
    "print(\"Outcomes:\",outcomes.columns)\n",
    "print(\"Updated computation of treatment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Confusion matrix for highest vs count based treatment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dh==0</th>\n",
       "      <th>dh==1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dl==0</th>\n",
       "      <td>4460</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dl==1</th>\n",
       "      <td>914</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dh==0  dh==1\n",
       "dl==0   4460      3\n",
       "dl==1    914    557"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reed import compute_confusion\n",
    "compute_confusion(treatments['redudl'],treatments['reduhl'],'dl','dh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Extract basic variables\n",
    "Extract a data set corresponding to the original paper we are working to extend - based on the table below;\n",
    "![image.png](images/original_paper_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 5727 individuals who are not present in waves q and s (51%)\n"
     ]
    }
   ],
   "source": [
    "from treatment_outcomes import simplify_employment\n",
    "from reed import regex_select\n",
    "\n",
    "def extract_basic_variables(df):\n",
    "    # age, sex, education in 2001, employment status in 2001\n",
    "    basic = df1[['xwaveid','ahgage','ahgsex','aedhigh1','aesdtl']].copy() \n",
    "\n",
    "    def simplify_education(v):\n",
    "        \"\"\"Simplify down to match categories in paper.\"\"\"\n",
    "        if v < 0 or v==10:\n",
    "            return np.nan # missing\n",
    "        if v < 3: #(above bachelors)\n",
    "            return 2\n",
    "        return v # < year 12:(9), year 12:(8), cert:(5), diploma/adv diploma:(4), bachelors/honours:(3)\n",
    "    \n",
    "    # simplify education & employment in line with baseline paper\n",
    "    basic['aesdtl']=basic['aesdtl'].apply(simplify_employment)\n",
    "    basic['aedhigh1'] = basic['aedhigh1'].apply(simplify_education)\n",
    "    \n",
    "    # bin age\n",
    "    basic['ahgage'] = pd.cut(basic['ahgage'],bins=[24,34,44,54,120])\n",
    "    \n",
    "    # dummy encode\n",
    "    basic = pd.get_dummies(basic,columns=['ahgage','ahgsex','aedhigh1','aesdtl'],drop_first=True)\n",
    "    \n",
    "    # add interactions between gender and other variables\n",
    "    age_edu_emp = regex_select(basic.columns,['^ahgage_','^aedhigh1_','^aesdtl_'])\n",
    "    basic = create_interaction_columns(basic,['ahgsex_2.0'],age_edu_emp)\n",
    "    basic['xwaveid'] = basic['xwaveid'].astype(int)\n",
    "    return basic\n",
    "\n",
    "if not test:\n",
    "    basic = extract_basic_variables(df1)\n",
    "    l0 = len(basic)\n",
    "    basic_with_outcomes = pd.merge(basic,treatment_outcomes,on='xwaveid',how='inner')\n",
    "    l1 = len(basic_with_outcomes)\n",
    "    print(f\"Dropped {l0-l1} individuals who are not present in waves {m} and {e} ({100*(l0-l1)/l0:.0f}%)\")\n",
    "    basic_with_outcomes.set_index('xwaveid',inplace=True)\n",
    "    basic_with_outcomes.to_csv(\"data/basic_variables.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Extract Full variable set\n",
    "Extract a 'kitchen sink' dataset with minimal filtering of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Filter out columns based on annotated spreadsheet\n",
    "Remove columns that have been manually marked as irrelevant or proxies to whether someone is already studying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def read_type_information():\n",
    "    headers = ['variable','vartype','format','label','long_label','varcat','relevance',\"0\"]\n",
    "    type_df = pd.read_csv(\"data/HILDAw1vardic.csv\",skiprows=4,index_col=None, names=headers)\n",
    "    type_df['relevance'] = type_df['relevance'].fillna(1).astype(int)\n",
    "    type_df.loc[type_df['label']=='ACAEPT','relevance'] = -1\n",
    "    return type_df\n",
    "\n",
    "def drop_irrelevant_columns_inplace(df, type_df):\n",
    "    irrelevant = list(type_df.loc[type_df['relevance']<1,'variable'])\n",
    "    irrelevant.remove('xwaveid')\n",
    "    df.drop(columns=irrelevant,inplace=True)\n",
    "    print(f\"Dropped {len(irrelevant)} irrelevant columns.\")\n",
    "    return irrelevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Fix types\n",
    "   - encode categorical values & strings as integers (ordinal rather than one-hot)\n",
    "   - transform dates into days past 01/01/1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def fix_types_inplace(df1):\n",
    "    # Reformat some of the columns\n",
    "    dates = [\n",
    "        \"ahhhqivw\",\n",
    "        \"ahhcompi\",\n",
    "        \"ahhcompf\",\n",
    "        \"ahhcomps\",\n",
    "        \"ahhidate\",\n",
    "        \"ahgdob1\",\n",
    "        \"ahgdob2\",\n",
    "        \"ahgdob3\",\n",
    "        \"ahgdob4\",\n",
    "        \"ahgdob5\",\n",
    "        \"ahgdob6\",\n",
    "        \"ahgdob\",\n",
    "    ]\n",
    "    string = ['ahhtitle']\n",
    "    categorical = [\n",
    "        'acca1',\n",
    "        'acca2',\n",
    "        'ahhmgfxd',\n",
    "        'ahhmgmxd',\n",
    "        'ahhp1',\n",
    "        'ahhp2',\n",
    "        'ahhp3',\n",
    "        'ahhpgfxd',\n",
    "        'ahhpgmxd',\n",
    "        'ahhpno',\n",
    "        'xwaveid',\n",
    "        'ahhid',\n",
    "        'ahhpid',\n",
    "        'ahhpcode',\n",
    "        'ahharea',\n",
    "        'ahhcd96',\n",
    "        'ats1',\n",
    "        'ats2',\n",
    "        'ats3',\n",
    "        'ats4',\n",
    "        'ats5',\n",
    "        'ats6',\n",
    "        'ahhdw',\n",
    "        'acsid1',\n",
    "        'acsid2',\n",
    "        'acsid3',\n",
    "        'acsid4',\n",
    "        'acsid5',\n",
    "        'acsid6',\n",
    "        'achid1',\n",
    "        'achid2',\n",
    "        'achid3',\n",
    "        'achid4',\n",
    "        'achid5',\n",
    "        'achid6',\n",
    "        'acpid1',\n",
    "        'acpid2',\n",
    "        'acpid3',\n",
    "        'acpid4',\n",
    "    ]\n",
    "\n",
    "    for c in categorical:\n",
    "        if c in df1.columns:\n",
    "            df1[c] = df1[c].replace(\"--\", \"\")\n",
    "            df1[c] = pd.to_numeric(df1[c])\n",
    "\n",
    "    # turn into days past epoch\n",
    "    basedate = pd.to_datetime('01/01/1900',format='%d/%m/%Y')    \n",
    "    for c in dates:\n",
    "        if c in df1.columns:\n",
    "            df1[c] = (pd.to_datetime(df1[c],format='%d/%m/%Y',errors='coerce')-basedate).dt.days \n",
    "\n",
    "    for c in string:\n",
    "        df1[c] = df1[c].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redundancy_with_nan(series, nbins):\n",
    "    \"\"\"\n",
    "    Compute the redundancy of a series after binning.\n",
    "    \n",
    "    Redundancy, in [0,1], measures how close the entropy of the distribution is to the maximum\n",
    "    entropy given the number of bins. Redundancy is minimized (=0) when the data is uniformly \n",
    "    distributed over the bins and maximised (=1) when all the data is in a single bin. \n",
    "    \"\"\"\n",
    "    if series.nunique() > nbins:\n",
    "        series = pd.cut(series, nbins, labels=False)\n",
    "            \n",
    "    counts = series.value_counts(dropna=False).values\n",
    "    if len(counts) == 1:\n",
    "        return 1\n",
    "    p = counts/counts.sum()\n",
    "    entropy = (-p*np.log(p)).sum()\n",
    "    redundancy = 1 - entropy/np.log(len(counts))\n",
    "    return redundancy\n",
    "\n",
    "def drop_redundant_columns_inplace(df,nbins, threshold):\n",
    "    r = np.zeros(len(df.columns))\n",
    "    for i,c in enumerate(df.columns):\n",
    "        r[i] = redundancy_with_nan(df[c],nbins)\n",
    "    \n",
    "    exclude = r > threshold\n",
    "    redundant = list(df.columns[exclude])\n",
    "    \n",
    "    r_values = dict(zip(df.columns[~exclude],r[~exclude]))\n",
    "    \n",
    "    df.drop(columns=redundant,inplace=True)\n",
    "    print(f\"Dropped {len(redundant)} columns with high redundancy/low entropy\")\n",
    "    return redundant, r_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(df, fillval = 0):\n",
    "    \"\"\"Compute the correlations between each pair of variables and return as a DataFrame in long form.\"\"\"\n",
    "    c = df.fillna(fillval).corr()\n",
    "    c1 = []\n",
    "    c2 = []\n",
    "    value = []\n",
    "    for i in range(c.shape[0]):\n",
    "        for j in range(c.shape[0]):\n",
    "            if i > j:\n",
    "                value.append(c.iloc[i, j])\n",
    "                c1.append(c.index[i])\n",
    "                c2.append(c.columns[j])\n",
    "    c = pd.DataFrame({'c1': c1, 'c2': c2, \"correlation\": value})\n",
    "    c['abs'] = c['correlation'].abs()\n",
    "    c.sort_values(['abs'],ascending=False,inplace=True)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def merge_correlated_pairs(df,r_vals, threshold, fillval=0):\n",
    "    \"\"\"\n",
    "    Merges pairs of variables with a correlation coefficient above the threshold.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    merged: list[str]\n",
    "        A list of all the column names that were merged into other columns.\n",
    "        \n",
    "    merges: {str:[str]} \n",
    "        A dict from column name to all the columns merged with that column.\n",
    "    \"\"\"\n",
    "\n",
    "    cs = compute_correlations(df, fillval)\n",
    "    \n",
    "    column_indicies = [\n",
    "        cs.columns.get_loc('c1'),\n",
    "        cs.columns.get_loc('c2'),\n",
    "        cs.columns.get_loc('abs')\n",
    "    ]\n",
    "\n",
    "    row = cs.iloc[0,column_indicies]\n",
    "    c1, c2, t = row\n",
    "    merges = defaultdict(list)\n",
    "    while t >= threshold:\n",
    "\n",
    "        # merge (keep lowest redundancy)\n",
    "        r1, r2 = r_vals[c1], r_vals[c2]\n",
    "        if r1 <= r2:\n",
    "            best, other = c1, c2\n",
    "        else:\n",
    "            best, other = c2, c1\n",
    "\n",
    "        merges[best].append(other)\n",
    "\n",
    "        # delete all rows involving merged in variable\n",
    "        drop_index = cs.index[(cs['c1']==other)|(cs['c2']==other)]\n",
    "\n",
    "        cs.drop(index=drop_index,inplace=True)\n",
    "        row = cs.iloc[0,column_indicies]\n",
    "        c1, c2, t = row\n",
    "    \n",
    "    merged = []\n",
    "    for v in merges.values():\n",
    "        merged.extend(v)\n",
    "        \n",
    "    df.drop(columns=merged,inplace=True)\n",
    "    return merged, merges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Automatic (very basic) column filtering\n",
    "   - drop columns where the proportion of data missing is above the maximum threshold\n",
    "   - drop columns that are constant (zero variance)\n",
    "   - drop columns that are very tightly correlated (based on correlation threshold) with another column that contains less missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def filter_raw_data(df1, missing_threshold=0.99, correlation_threshold=0.99):\n",
    "    columns_dropped = {} # keep track of why each column was dropped\n",
    "    \n",
    "    type_df = read_type_information()\n",
    "    irrelevant = drop_irrelevant_columns_inplace(df1,type_df)\n",
    "    add_list_to_dict(irrelevant,columns_dropped,'invalid/irrelevant')\n",
    "\n",
    "    fix_types_inplace(df1)\n",
    "    \n",
    "    constant = drop_constant_columns(df1)\n",
    "    add_list_to_dict(constant,columns_dropped,'constant')\n",
    "    \n",
    "    if redundant_threshold < 1:\n",
    "        redundant, r_vals = drop_redundant_columns_inplace(df1, 100, redundant_threshold)\n",
    "        add_list_to_dict(redundant,columns_dropped,'high-redundancy')\n",
    "    \n",
    "    if missing_threshold < 1:\n",
    "        mostly_missing = drop_mostly_missing_columns(df1, threshold = missing_threshold)\n",
    "        add_list_to_dict(mostly_missing, columns_dropped, 'mostly-missing')\n",
    "    \n",
    "    if correlation_threshold < 1:\n",
    "        dropped, merges = merge_correlated_pairs(df1, r_vals, correlation_threshold,fillval=0)\n",
    "        add_list_to_dict(dropped, columns_dropped, 'merged')\n",
    "    \n",
    "    \n",
    "    print(\"Processed data, with shape:\",df1.shape)\n",
    "    return df1, columns_dropped, r_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Save the data to file\n",
    "Save the data to file for subsequent model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 403 irrelevant columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsteinberg/code/re-education/clean.py:20: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  std = df.std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 269 columns that are constant or entirely missing\n",
      "Dropped 1879 columns with high redundancy/low entropy\n",
      "Dropping 385 columns with more than 90% missing \n",
      "Processed data, with shape: (11168, 845)\n",
      "Dropped 5727 individuals who are not present in waves q and s (51%)\n",
      "Written data of shape (5441, 857) to: data/all_vars.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def write_data(X, treatment_outcomes,filename):\n",
    "    filepath = os.path.join(\"data\",filename)\n",
    "    l0 = len(X)\n",
    "    df = pd.merge(X, treatment_outcomes, on=['xwaveid'],how='inner')\n",
    "    l1 = len(df)\n",
    "    print(f\"Dropped {l0-l1} individuals who are not present in waves {m} and {e} ({100*(l0-l1)/l0:.0f}%)\")\n",
    "    df.set_index('xwaveid',inplace=True)\n",
    "    df.to_csv(filepath,index=True)\n",
    "    print(f\"Written data of shape {df.shape} to:\",filepath)\n",
    "    assert (basic_with_outcomes.index == df.index).all(), \"index should be the same across datasets\"\n",
    "\n",
    "if not test:\n",
    "    X, columns_dropped, r_vals = filter_raw_data(df1.copy(), missing_threshold=missing_threshold,correlation_threshold=correlation_threshold)\n",
    "    write_data(X, treatment_outcomes, \"all_vars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Feature selection using wage 5 years after initial wave as labels\n",
    "\n",
    "This is based on the premise that the features that are predictive of the change in wage due to returning to education are likely to be the same set of features that are important for predicting wage more generally. This allows us to do supervised feature selection without worrying so much about over-fitting to the data, as we are not using the final labels we are training against. \n",
    "\n",
    "Note: we can't use initial wage as the target because then we end up selecting features that are simply proxies to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cinspect.dimension import effective_rank\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 403 irrelevant columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsteinberg/code/re-education/clean.py:20: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  std = df.std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 309 columns that are constant or entirely missing\n",
      "Dropped 1769 columns with high redundancy/low entropy\n",
      "Dropping 395 columns with more than 90% missing \n",
      "Processed data, with shape: (19914, 855)\n"
     ]
    }
   ],
   "source": [
    "# Make a dataset for feature selection that uses the value of the target feature 5 years after the initial wave as the target\n",
    "\n",
    "def create_dataset_to_predict_outcome_five_years_after_initial_wave(target):\n",
    "    indx = string.ascii_lowercase.index(s)+5\n",
    "    post_start = string.ascii_lowercase[indx]\n",
    "   \n",
    "    df0, meta1 = pyreadstat.read_sav(f'data/part1/Combined {s}190{sfx}.sav') \n",
    "    outcomes_post = compute_outcomes(df0, s, post_start, release)\n",
    "    outcomes_post['xwaveid'] = outcomes_post['xwaveid'].astype(int)\n",
    "    outcomes_post.set_index('xwaveid',inplace=True)\n",
    "    X, columns_dropped, r_vals = filter_raw_data(df0, missing_threshold=0.9,correlation_threshold=0.9)\n",
    "    X['xwaveid'] = X['xwaveid'].astype(int)\n",
    "    X.set_index('xwaveid',inplace=True)\n",
    "    o = outcomes_post.join(X)\n",
    "    features = df0.columns\n",
    "    y = o[target].values\n",
    "    valid_rows = ~np.isnan(y)\n",
    "\n",
    "    y = y[valid_rows]\n",
    "    X = o.loc[valid_rows,features]\n",
    "    Xs = StandardScaler().fit_transform(X.fillna(0))\n",
    "    Xs = pd.DataFrame(Xs, columns=features)\n",
    "    return Xs, y\n",
    "\n",
    "if not test:\n",
    "    target = 'y_wscei'\n",
    "    Xs, ys = create_dataset_to_predict_outcome_five_years_after_initial_wave(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Univariate features selectiong: Select k-best\n",
    "\n",
    "Takes no account of correlation between features, results in a matrix with a low effective rank (compared with it's actual rank). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "if not test:\n",
    "    selector = SelectKBest(f_regression, k=10)\n",
    "    selector.fit(Xs,ys)\n",
    "    effective_rank(Xs[selector.get_feature_names_out()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Multivariate-feature selection: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+08, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+08, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.910e+07, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.571e+07, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.409e+07, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.526e+07, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.981e+07, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e+07, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e+07, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.074e+06, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.011e+06, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.828e+06, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.075e+06, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/dsteinberg/.virtualenvs/re-education/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.651e+05, tolerance: 6.560e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see how many features we get as a function of regularisation strength. \n",
    "# we could use prediction accuracy as a rough estimate of how many features to use\n",
    "# note that we are not removing people currently studying, so the model may select features relating to current study\n",
    "# these will be dropped before being written as they are constant. \n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "if not test:\n",
    "    alphas = np.logspace(-1,2,40)  \n",
    "    n_selected = []\n",
    "    for alpha in alphas:\n",
    "        ls = Lasso(alpha=alpha)\n",
    "        selector = SelectFromModel(ls)\n",
    "        selector.fit(Xs,ys)\n",
    "        n_selected.append(len(selector.get_feature_names_out()))\n",
    "\n",
    "    plt.semilogx(alphas, n_selected)\n",
    "    plt.xlabel(\"alpha\")\n",
    "    plt.ylabel(\"number of features selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_for_num_features(num_features, n_selected, alphas):\n",
    "    n_selected = np.array(n_selected)\n",
    "    indx = np.nanargmin(np.abs(n_selected - num_features))\n",
    "    return alphas[indx], n_selected[indx]\n",
    "\n",
    "def select_features(num_features, n_selected, alphas, Xs, ys):\n",
    "    print(f\"Generating dataset with approximately {num_features} features\" )\n",
    "    alpha, _ = get_alpha_for_num_features(num_features,n_selected, alphas)\n",
    "    ls = Lasso(alpha=alpha)\n",
    "    selector = SelectFromModel(ls)\n",
    "    selector.fit(Xs,ys)\n",
    "    f_selected = selector.get_feature_names_out()\n",
    "    print(\"number of features selected:\",len(f_selected))\n",
    "    print(\"effective rank on selection matrix:\",effective_rank(Xs[f_selected]))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    return f_selected\n",
    "\n",
    "def write_selected_featureset(X, columns_dropped, features, tag):\n",
    "    selection = ['xwaveid']\n",
    "    missing = []\n",
    "    for f in features:\n",
    "        if f in X.columns:\n",
    "            selection.append(f)\n",
    "        else:\n",
    "            reason = columns_dropped.get(f,\"unkown\")\n",
    "            print(f\"Column {f} not present in X, reason:{reason}\")\n",
    "    \n",
    "    write_data(X[selection], treatment_outcomes, f\"all_lasso_selected_{tag}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset with approximately 10 features\n",
      "number of features selected: 11\n",
      "effective rank on selection matrix: 5.955208107031399\n",
      "\n",
      "\n",
      "Generating dataset with approximately 20 features\n",
      "number of features selected: 21\n",
      "effective rank on selection matrix: 10.961410967696544\n",
      "\n",
      "\n",
      "Generating dataset with approximately 50 features\n",
      "number of features selected: 51\n",
      "effective rank on selection matrix: 24.616498296346048\n",
      "\n",
      "\n",
      "Generating dataset with approximately 100 features\n",
      "number of features selected: 95\n",
      "effective rank on selection matrix: 47.00943127122669\n",
      "\n",
      "\n",
      "Dropped 403 irrelevant columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsteinberg/code/re-education/clean.py:20: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  std = df.std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 269 columns that are constant or entirely missing\n",
      "Dropped 1879 columns with high redundancy/low entropy\n",
      "Dropping 0 columns with more than 99% missing \n",
      "Processed data, with shape: (11168, 1741)\n",
      "Dropped 5727 individuals who are not present in waves q and s (51%)\n",
      "Written data of shape (5441, 24) to: data/all_lasso_selected_10.csv\n",
      "Column acapeft not present in X, reason:constant\n",
      "Column aedfts not present in X, reason:constant\n",
      "Dropped 5727 individuals who are not present in waves q and s (51%)\n",
      "Written data of shape (5441, 32) to: data/all_lasso_selected_20.csv\n",
      "Column aedqstdy not present in X, reason:constant\n",
      "Column acapeft not present in X, reason:constant\n",
      "Column aedfts not present in X, reason:constant\n",
      "Dropped 5727 individuals who are not present in waves q and s (51%)\n",
      "Written data of shape (5441, 61) to: data/all_lasso_selected_50.csv\n",
      "Column aedqstdy not present in X, reason:constant\n",
      "Column acapeft not present in X, reason:constant\n",
      "Column acapept not present in X, reason:constant\n",
      "Column aedfts not present in X, reason:constant\n",
      "Dropped 5727 individuals who are not present in waves q and s (51%)\n",
      "Written data of shape (5441, 104) to: data/all_lasso_selected_100.csv\n",
      "ahifapti DV: Household financial year Australian public transfers (inc family benefits) ($) [imputed]\n",
      "ahgsex HF3 Sex\n",
      "ahgrf HF10 Follow-up stage individual interview outcome\n",
      "ahgscq HF11 Overall self completion office code\n",
      "aoidvryf DV: Imputation flag financial year dividends plus royalties including nil\n",
      "awscef DV: Imputation flag current weekly gross wages & salary - all jobs\n",
      "awscoef DV: Imputation flag current weekly gross wages & salary - other jobs\n",
      "awsfef DV: Imputation flag financial year gross wages & salary\n",
      "ajbmpgj E29 Percent chance will find and accept job at least as good as current job\n",
      "ajbmwpsz E33 Number employed at place of work\n",
      "awsfga G20 Gross financial year wages and salaries ($)\n",
      "ancage2 H3b Age of child - Non-resident child 0002\n",
      "aicprob H28 Is likely to have a child in the future\n",
      "ajbmo6s DV: AUSEI06 occupational status scale, current main job\n",
      "acapeft DV: Per cent time spent in FT education in last financial year\n",
      "ajbcasab DV: Casual worker (ABS definition: no paid holiday leave, no paid sick leave)\n",
      "atcyng DV: Age youngest own child (excl. resident foster/step)\n",
      "aedfts DV: Full-time student\n",
      "atcnr DV: Number of own non-resident children\n",
      "awscme DV: Current weekly gross wages & salary, main job, includes estimated from net ($)\n",
      "apawkmfh SCQ:F4f Work-family balance: Miss out on home/family activities\n"
     ]
    }
   ],
   "source": [
    "if not test:\n",
    "    f10 = select_features(10, n_selected, alphas, Xs, ys)\n",
    "    f20 = select_features(20, n_selected, alphas, Xs, ys)\n",
    "    f50 = select_features(50, n_selected, alphas, Xs, ys)\n",
    "    f100 = select_features(100, n_selected, alphas, Xs, ys)\n",
    "\n",
    "    X, columns_dropped, r_vals = filter_raw_data(df1.copy(), missing_threshold=0.99,correlation_threshold=1)\n",
    "\n",
    "    write_selected_featureset(X, columns_dropped, f10, 10)\n",
    "    write_selected_featureset(X, columns_dropped, f20, 20)\n",
    "    write_selected_featureset(X, columns_dropped, f50, 50)\n",
    "    write_selected_featureset(X, columns_dropped, f100, 100)\n",
    "    for f in f20:\n",
    "        print(f, meta1.column_names_to_labels.get(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Unsupervised feature selection\n",
    "\n",
    "Greedy selection of features to optimise effective rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cinspect.dimension import greedy_feature_selection, effective_rank\n",
    "\n",
    "# features_to_select = 100\n",
    "# Xs = StandardScaler().fit_transform(X.fillna(0))\n",
    "# selected, vals = greedy_feature_selection(\n",
    "#     Xs, effective_rank, \n",
    "#     initial_col=4, num_to_select=features_to_select\n",
    "# )\n",
    "\n",
    "# selected_cols = [X.columns[i] for i in selected]\n",
    "# X_su = X[selected_cols]\n",
    "# print(\"number of features selected:\",len(selected_cols))\n",
    "# print(\"effective rank:\",effective_rank(Xs[selected]))\n",
    "# write_data(X_su.reset_index(), treatment_outcomes, \"all_unsupervised_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
