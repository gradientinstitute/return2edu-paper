{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import re\n",
    "import string\n",
    "import sklearn\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from skopt import BayesSearchCV\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from reed import *\n",
    "from cinspect import dependence, importance\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# set global notebook options\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 500\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'y_Dwsce'#'y_wsce'\n",
    "treatment = 'redufl'\n",
    "optimisation_metric = 'neg_mean_squared_error'\n",
    "log_outcome=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 592 rows missing treatment or outcome.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"all_vars_950.csv\",index_col='xwaveid')\n",
    "drop_missing_treatment_or_outcome(data, treatment, outcome)\n",
    "if log_outcome:\n",
    "    data[outcome] = np.log(data[outcome]+data[outcome].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def construct_models():\n",
    "    models = [\n",
    "        Model('ridge',Ridge(), \n",
    "              parameters = {\n",
    "                  'alpha':np.logspace(-1,4,30)\n",
    "              }\n",
    "        ),\n",
    "        Model('lasso',Lasso(),\n",
    "              parameters = {\n",
    "                  'alpha':np.logspace(-2,4,30)\n",
    "              }\n",
    "        ), \n",
    "        Model('gbr',GradientBoostingRegressor(n_iter_no_change=20, max_depth=2),\n",
    "              parameters = {\n",
    "                'max_features':[10,20,40,60,80],\n",
    "                'learning_rate':np.logspace(-3,0,10),\n",
    "                'min_samples_leaf':np.logspace(0,3,10).astype(int)\n",
    "              }\n",
    "        ),\n",
    "    ]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -s exclude_vars,seperate_and_transform_data direct_regression.py\n",
    "def exclude_vars():\n",
    "    \"\"\"Return a list of variables that should not be included as features.\"\"\"\n",
    "    treatments = ['^reduhl$', '^rehllt$', '^redudl$', '^redufl$', '^redllt$', '^refllt$']\n",
    "    outcomes = ['^rlwage$', '^mh$', '^mhbm$', '^wkhr$', '^y_']\n",
    "    other = [\n",
    "        '^p_rcom',\n",
    "        '^p_rdf',\n",
    "        '^p_cotrl',\n",
    "        '^xwaveid$',\n",
    "        'p_rcom18'  # ?\n",
    "        '^aedcq',  # indicate studying at start - these people should already have been removed\n",
    "        '^abnfsty',\n",
    "        '^aedcqfpt',\n",
    "        '^aedqstdy'\n",
    "    ]\n",
    "    exclude = treatments + outcomes + other\n",
    "    return exclude\n",
    "\n",
    "def seperate_and_transform_data(data, treatment, outcome):\n",
    "\n",
    "    transform = Pipeline([\n",
    "        ('impute_missing', SimpleImputer()),\n",
    "        ('scale', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    exclude = exclude_vars()\n",
    "\n",
    "    control, treated = treatment_control_split(data, treatment)\n",
    "    features = regex_select(data.columns, exclude, exclude=True)\n",
    "    X0, y0 = split_and_transform(control, features, outcome, transform)\n",
    "    X1, y1 = split_and_transform(treated, features, outcome, transform)\n",
    "\n",
    "    # construct the full dataset (remove ordering by treatment in case of any order dependance in fit)\n",
    "    X = np.vstack((X0, X1))\n",
    "    y = np.concatenate((y0, y1))\n",
    "    indx = np.arange(len(y))\n",
    "    np.random.shuffle(indx)\n",
    "    X = X[indx, :]\n",
    "    y = y[indx]\n",
    "\n",
    "    return X0, X1, y0, y1, X, y, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treated:773, Control:4181\n"
     ]
    }
   ],
   "source": [
    "X0, X1, y0, y1, X, y, features = seperate_and_transform_data(data, treatment, outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -s print_unconditional_effects direct_regression.py\n",
    "def print_unconditional_effects(data, treatment, y0, y1):\n",
    "    print(f\"Proportion Treated:{100*data[treatment].mean():.0f}%\")\n",
    "    print(f\"Average outcome under Control:{y0.mean():.2f}±{y0.std()/np.sqrt(len(y0)):.2f}\")\n",
    "    print(f\"Average outcome under Treatment:{y1.mean():.2f}±{y1.std()/np.sqrt(len(y1)):.2f}\")\n",
    "    print(f\"Unadjusted treatment estimate {y1.mean() - y0.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion Treated:16%\n",
      "Average outcome under Control:76.98±14.61\n",
      "Average outcome under Treatment:425.08±37.85\n",
      "Unadjusted treatment estimate 348.10\n"
     ]
    }
   ],
   "source": [
    "print_unconditional_effects(data, treatment, y0, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "evaluation_metrics = ('r2','neg_mean_squared_error')\n",
    "\n",
    "\n",
    "def nested_cross_val(\n",
    "    load_from_cache=False, \n",
    "    cache_name = \"nested_cv_results.pkl\",\n",
    "):\n",
    "    if load_from_cache:\n",
    "        with open(cache_name,'rb') as f:\n",
    "            models, results = pickle.load(f)\n",
    "            \n",
    "    else:\n",
    "        models = construct_models()\n",
    "        results = {}\n",
    "        for model in models:\n",
    "            print(f\"Fitting {model.name} ...\",end='')\n",
    "            results0 = model.nested_cv_fit_evaluate(X0,y0,optimisation_metric,evaluation_metrics)\n",
    "            results1 = model.nested_cv_fit_evaluate(X1,y1,optimisation_metric,evaluation_metrics)\n",
    "            results[model.name] = (results0, results1)\n",
    "            print(\"Done\")\n",
    "        \n",
    "        print(f\"Caching results to {cache_name}\")\n",
    "        with open(cache_name,'wb') as f:\n",
    "            pickle.dump((models,results),f)\n",
    "            \n",
    "    return models,results\n",
    " \n",
    "\n",
    "models, results = nested_cross_val(load_from_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACE</th>\n",
       "      <th>ACE_std</th>\n",
       "      <th>control_r2</th>\n",
       "      <th>control_r2_std</th>\n",
       "      <th>treated_r2</th>\n",
       "      <th>treated_r2_std</th>\n",
       "      <th>control_neg_mean_squared_error</th>\n",
       "      <th>control_neg_mean_squared_error_std</th>\n",
       "      <th>treated_neg_mean_squared_error</th>\n",
       "      <th>treated_neg_mean_squared_error_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>348.70</td>\n",
       "      <td>15.14</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-698,017.69</td>\n",
       "      <td>78,428.38</td>\n",
       "      <td>-992,360.87</td>\n",
       "      <td>326,884.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>349.53</td>\n",
       "      <td>9.82</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-657,597.47</td>\n",
       "      <td>84,078.73</td>\n",
       "      <td>-991,618.50</td>\n",
       "      <td>166,074.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbr</th>\n",
       "      <td>483.75</td>\n",
       "      <td>142.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-677,879.90</td>\n",
       "      <td>125,161.17</td>\n",
       "      <td>-1,044,093.85</td>\n",
       "      <td>205,093.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACE  ACE_std  control_r2  control_r2_std  treated_r2  treated_r2_std  \\\n",
       "ridge 348.70    15.14        0.22            0.06        0.11            0.03   \n",
       "lasso 349.53     9.82        0.26            0.04        0.10            0.03   \n",
       "gbr   483.75   142.32        0.25            0.06        0.06            0.06   \n",
       "\n",
       "       control_neg_mean_squared_error  control_neg_mean_squared_error_std  \\\n",
       "ridge                     -698,017.69                           78,428.38   \n",
       "lasso                     -657,597.47                           84,078.73   \n",
       "gbr                       -677,879.90                          125,161.17   \n",
       "\n",
       "       treated_neg_mean_squared_error  treated_neg_mean_squared_error_std  \n",
       "ridge                     -992,360.87                          326,884.08  \n",
       "lasso                     -991,618.50                          166,074.33  \n",
       "gbr                     -1,044,093.85                          205,093.54  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def estimate_causal_effect(X, models0, models1):\n",
    "    tau = []\n",
    "    for e0, e1 in zip(models0,models1):\n",
    "        y0 = e0.predict(X)\n",
    "        y1 = e1.predict(X)\n",
    "        tau.append(y1-y0)\n",
    "    \n",
    "    # array of shape len(modelsi),len(X)\n",
    "    cate = np.array(tau) \n",
    "    \n",
    "    # array of shape len(modelsi) with the ate estimate for each sample\n",
    "    ate = np.mean(cate,axis=1) \n",
    "    return ate\n",
    "\n",
    "rows = []\n",
    "index = []\n",
    "for model_name, r in results.items():\n",
    "    tau = estimate_causal_effect(X, r[0]['estimator'],r[1]['estimator'])\n",
    "    row = {'ACE':tau.mean(),'ACE_std':tau.std()}\n",
    "    for m in evaluation_metrics:\n",
    "        key = f'test_{m}'\n",
    "        for name, result in zip(('control','treated'),r):\n",
    "            label=f\"{name}_{m}\"\n",
    "            label_std=f\"{label}_std\"\n",
    "            row[label]= result[key].mean()\n",
    "            std = result[key].std()\n",
    "            row[label_std] = result[key].std()\n",
    "    rows.append(row)\n",
    "    index.append(model_name)\n",
    "metrics = pd.DataFrame(rows,index=index)\n",
    "\n",
    "with pd.option_context('display.float_format', '{:,.2f}'.format):\n",
    "    display(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c,t = results['ridge'][0],results['ridge'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_coef = pd.DataFrame({\n",
    "#     \"feature\":features,\n",
    "#     'coef0':c['estimator'][0].best_estimator_.coef_,\n",
    "#     'coef1':c['estimator'][1].best_estimator_.coef_\n",
    "# })\n",
    "# absv = np.vstack((feature_coef['coef0'].abs().values,feature_coef['coef1'].abs().values)).T\n",
    "# feature_coef['importance'] = absv.max(axis=1)\n",
    "# feature_coef['hetero'] = (feature_coef['coef1']-feature_coef['coef0']).abs()\n",
    "# feature_coef.sort_values('importance',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_coef.sort_values('hetero',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,2,figsize=(15,5),sharey=True)\n",
    "# ax[0].bar(metrics.index, metrics['control_r2'], yerr=metrics['control_r2_std'], align='center', alpha=0.5, capsize=10)\n",
    "# ax[1].bar(metrics.index, metrics['treated_r2'], yerr=metrics['treated_r2_std'], align='center', alpha=0.5,capsize=10)\n",
    "# ax[0].set_ylabel('$R^2$')\n",
    "# ax[0].set_title('control model')\n",
    "# ax[1].set_title('treated model');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def extract_params(estimator):\n",
    "#     return estimator.coef_\n",
    "\n",
    "# def bootstrapped_cross_val(load_from_cache=False, cache_name=\"bootstrap_cv_results.pkl\", samples=10):\n",
    "#     if load_from_cache:\n",
    "#         with open(cache_name, 'rb') as f:\n",
    "#             results = pickle.load(f)\n",
    "#     else:\n",
    "#         models = construct_models()\n",
    "#         results = {}\n",
    "#         start = time.time()\n",
    "#         for model in models:\n",
    "#             print(f\"Fitting {model.name} ...\",end='')\n",
    "#             results0 = model.bootstrap_cv_evaluate(X0,y0,optimisation_metric,extract_params,\n",
    "#                                                    bootstrap_samples=samples,return_estimator=True)\n",
    "#             results1 = model.bootstrap_cv_evaluate(X1,y1,optimisation_metric,extract_params,\n",
    "#                                                    bootstrap_samples=samples,return_estimator=True)\n",
    "#             results[model.name] = (results0, results1)\n",
    "#             print(\"Done\")\n",
    "#         total = time.time()-start\n",
    "#         print(f\"Total time:{total} seconds\")\n",
    "#         print(f\"Caching results to: {cache_name}\")\n",
    "#         with open(cache_name,'wb') as f:\n",
    "#             pickle.dump(results,f)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# bootstrap_results = bootstrapped_cross_val(load_from_cache=False,samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name, (results0, results1) in bootstrap_results.items():\n",
    "#     models0 = [r['estimator'] for r in results0]\n",
    "#     models1 = [r['estimator'] for r in results1]\n",
    "#     ate = estimate_causal_effect(X,models0, models1)\n",
    "#     print(model_name, ate.mean(),ate.std()/np.sqrt(len(ate)-1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# def hyperparam_distributions(samples) -> {str:[]}:\n",
    "#     \"\"\"Returns a dict from hyper-parameter name to the best values for that hyper-parameter over the samples.\"\"\"\n",
    "#     distributions = defaultdict(list)\n",
    "#     for sample in samples:\n",
    "#         h = sample['estimator'].best_params_\n",
    "#         for key, value in h.items():\n",
    "#             distributions[key].append(value)\n",
    "#     return distributions\n",
    "\n",
    "# def plot_hyperparam_distributions(samples, title) -> None:\n",
    "#     distributions = hyperparam_distributions(samples)\n",
    "#     k = len(distributions)\n",
    "#     fig, axes = plt.subplots(1,k,figsize=(k*5,4))\n",
    "#     if k == 1:\n",
    "#         axes = [axes]\n",
    "#     for i, (key, values) in enumerate(distributions.items()):\n",
    "#         ax = axes[i]\n",
    "#         ax.hist(values)\n",
    "#         ax.set_title(title)\n",
    "#         ax.set_xlabel(key)\n",
    "#         ax.set_ylabel('count')\n",
    "#     return fig,axes\n",
    "\n",
    "# for model, (results0, results1) in bootstrap_results.items():\n",
    "#     plot_hyperparam_distributions(results0,f\"{model}-control\")\n",
    "#     plot_hyperparam_distributions(results1,f\"{model}-treated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO, could also think about visualising distribution of coefficeints for linear models. \n",
    "# TODO, why is this results so different to what I am getting from T-learners in econml"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}